{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some RDDs\n",
    "### From Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [0,1,2,3,4,5,6,7,8,9]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myRDD = sc.parallelize(data)\n",
    "myRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fooRDD = sc.textFile('foo.txt')\n",
    "fooRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fooRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(fooRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(fooRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addStuff(x):\n",
    "    return x + 200\n",
    "\n",
    "addStuff(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "funcRDD = myRDD.map(addStuff)\n",
    "funcRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambdaRDD = myRDD.map(lambda x: x + 200)\n",
    "lambdaRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuples and Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tupleRDD = sc.parallelize(\n",
    "    [(1,2), \n",
    "     (1,5), \n",
    "     (2,6), (5,7), (6,1), (5,10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tupleRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tupleRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newTupleRDD = tupleRDD.map(lambda x: x + 200)\n",
    "newTupleRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newTupleRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newTupleRDD = tupleRDD.map(lambda (x,y): (x, y+200))\n",
    "newTupleRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newTupleRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myRDD = sc.parallelize([1,2,3,4,5])\n",
    "\n",
    "myTupleRDD = myRDD.map(lambda x: (x, x+200))\n",
    "myTupleRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flatMapRDD = myRDD.flatMap(lambda x: (x, x+200))\n",
    "flatMapRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listRDD = sc.parallelize([\n",
    "        [1,2,3,4,5],\n",
    "        [6,7,8,9,10],\n",
    "        [10,11,12,13,14,15]\n",
    "    ])\n",
    "listRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listRDD.map(lambda x: x + [5]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listRDD.flatMap(lambda x: x + [5]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key/Value Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tupleRDD = sc.parallelize([(1,2), (1,5), (2,6), (5,7), (6,1), (5,10)])\n",
    "tupleRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tupleRDD.sortByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tupleRDD.reduceByKey(lambda x,y: x + y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "tupleRDD.reduceByKey(add).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(tupleRDD\n",
    " .map(lambda (x,y): (x*3, y))\n",
    " .reduceByKey(add).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sc.textFile('wordcount.txt')\n",
    "data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mappedData = data.map(lambda line: line.split(' '))\n",
    "mappedData.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flatMappedData = data.flatMap(lambda line: line.split(' '))\n",
    "flatMappedData.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = flatMappedData.map(lambda word: (word, 1))\n",
    "words.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordcounts = words.reduceByKey(lambda x,y: x + y)\n",
    "wordcounts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordcounts.takeOrdered(10, lambda (word,freq): word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordcounts.takeOrdered(10, lambda (word,freq): -1*freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = (data.flatMap(lambda x: x.split(' '))\n",
    "          .map(lambda x: (x, 1))\n",
    "          .reduceByKey(lambda x,y: x + y)\n",
    "          .sortBy(lambda (word,freq): -1*freq))\n",
    "counts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcast variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigVar = sc.parallelize(range(1000000)).zipWithIndex().collectAsMap()\n",
    "myRDD = sc.parallelize(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bigVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def myfunc(x, var):\n",
    "    if x in var:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "myRDD.map(lambda x: myfunc(x, bigVar)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def myfunc_broadcast(x):\n",
    "    var = bigVarBroadcast.value\n",
    "    if x in var:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "bigVarBroadcast = sc.broadcast(bigVar)\n",
    "\n",
    "myRDD.map(lambda x: myfunc_broadcast(x)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "dense = [0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "sys.getsizeof(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparse = (100,[5,16],[1,1])\n",
    "sys.getsizeof(sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseVector\n",
    "\n",
    "sv = SparseVector(100,[1,5,7,12],[1.0,1.0,1.0,1.0])\n",
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sv.toArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import LabeledPoint\n",
    "\n",
    "lp = LabeledPoint(1.0, [3,4,5,6,7])\n",
    "lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lp.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lp.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD of LabeledPoints with SparseVector for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeledRDD = sc.parallelize([\n",
    "        LabeledPoint(1.0, SparseVector(1000,[1,5,7,12],[1.0,1.0,1.0,1.0])),\n",
    "        LabeledPoint(1.0, SparseVector(1000,[12,15,27,42],[1.0,1.0,1.0,1.0])),\n",
    "        LabeledPoint(0.0, SparseVector(1000,[5,15,17,102],[1.0,1.0,1.0,1.0])),\n",
    "        LabeledPoint(1.0, SparseVector(1000,[100,500,700],[1.0,1.0,1.0])),\n",
    "        LabeledPoint(0.0, SparseVector(1000,[1],[1.0])),\n",
    "])\n",
    "labeledRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "\n",
    "lr = LogisticRegressionWithSGD()\n",
    "model = lr.train(labeledRDD)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.predict(SparseVector(1000,[1,500,702],[1.0,1.0,1.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "scoresAndLabels = sc.parallelize([\n",
    "        (0.2, 1.0),\n",
    "        (0.3, 0.0),\n",
    "        (0.4, 0.0),\n",
    "        (0.5, 0.0),\n",
    "        (0.7, 0.0),\n",
    "        (0.8, 1.0),\n",
    "        (0.8, 0.0),\n",
    "        (0.9, 1.0)\n",
    "    ])\n",
    "metrics = BinaryClassificationMetrics(scoresAndLabels)\n",
    "metrics.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?metrics.falsePositiveRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "predictionsAndLabels = sc.parallelize([\n",
    "        (0.0, 1.0),\n",
    "        (0.0, 0.0),\n",
    "        (0.0, 0.0),\n",
    "        (0.0, 0.0),\n",
    "        (0.0, 0.0),\n",
    "        (1.0, 1.0),\n",
    "        (1.0, 0.0),\n",
    "        (1.0, 1.0)\n",
    "    ])\n",
    "metrics = MulticlassMetrics(predictionsAndLabels)\n",
    "metrics.truePositiveRate(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predicted instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainRDD = sc.parallelize([\n",
    "        LabeledPoint(1.0, SparseVector(1000,[1,5,7,12],[1.0,1.0,1.0,1.0])),\n",
    "        LabeledPoint(1.0, SparseVector(1000,[12,15,27,42],[1.0,1.0,1.0,1.0])),\n",
    "        LabeledPoint(0.0, SparseVector(1000,[5,15,17,102],[1.0,1.0,1.0,1.0])),\n",
    "        LabeledPoint(1.0, SparseVector(1000,[100,500,700],[1.0,1.0,1.0])),\n",
    "        LabeledPoint(0.0, SparseVector(1000,[1],[1.0])),\n",
    "])\n",
    "testRDD = sc.parallelize([\n",
    "        LabeledPoint(1.0, SparseVector(1000,[10,15,17,120],[1.0,1.0,1.0,1.0])),\n",
    "        LabeledPoint(1.0, SparseVector(1000,[12,27,42],[1.0,1.0,1.0])),\n",
    "        LabeledPoint(0.0, SparseVector(1000,[15,17,102],[1.0,1.0,1.0])),\n",
    "        LabeledPoint(1.0, SparseVector(1000,[10,150,700],[1.0,1.0,1.0])),\n",
    "        LabeledPoint(0.0, SparseVector(1000,[1,2],[1.0,1.0])),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selectedModel = LogisticRegressionWithSGD.train(trainRDD)\n",
    "predictionAndLabel = testRDD.map(lambda p : (float(selectedModel.predict(p.features)), p.label))\n",
    "auc = BinaryClassificationMetrics(predictionAndLabel).areaUnderROC\n",
    "print 'AUC:', auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
